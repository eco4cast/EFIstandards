# FORECAST ARCHIVING

## Short-term distribution and long-term archiving

EFI does not mandate any single, specific repository to be used for archiving forecasts, but rather provides the following recommendations for the attributes of what makes a good forecast repository. At a high-level, these guidelines start from the principle that data should be FAIR (Findable, Accessible, Interoperable, and Reusable) [@wilkinson_fair_2016], but also acknowledge additional challenges that are common to forecasts that may not be as important for other data types. For example, forecasts have two concepts of time (see subsection “Dimensions”), reference_datetime and datetime, which most searchable archives are not set up to accommodate. Within forecasts, any individual datetime may show up numerous times in an archive, each associated with a different reference_datetime and datetime. Similarly, the uncertainty dimensions in forecasts are critical to forecasts and tend to have a richer representation of uncertainty than most data products (see subsection “Dimensions”). Combined these factors make forecast outputs high dimensional. Forecasts also share challenges with other streaming data sources, where records are continuously being appended with the latest forecasts. Similarly, low latency between when forecasts are generated and when they become available is essential to the usefulness of many ecological forecasts.

Because of these challenges, EFI finds it useful to make a distinction between the short-term distribution and long-term archiving of ecological forecasts. Services for short-term distribution will generally need to be machine-writable to allow forecast workflows to push new forecasts automatically. Again, this is critical when forecasts are made frequently or when users need to be able to access forecasts in a timely manner. However, it is currently rare for genuinely persistent archives to be truly machine-writable (e.g., most machine-writable archives require keys that need to be manually refreshed every few days, which is an unrealistic barrier to automation). Furthermore, the frequency at which forecasts are generated can present challenges to how identifiers are assigned to forecasts. Forecasting projects can easily generate thousands of forecasts a year (e.g., daily forecasts over multiple sites with multiple models), which can overwhelm the ability of many archives to mint DOIs as identifiers. In addition, if every forecast has its own DOI this reduces the findability of forecasts. Additionally, users do not want to have to report thousands of DOIs in a publication. Creating a distinction between a short-term machine-writable service for forecast distribution and a separate long-term service for persistent archiving easily addresses these needs. 

The EFI convention specifically recommends pushing forecasts from distribution sites to persistent archives on a periodic basis (e.g., annually) and that DOI minting be associated with these periodic archives rather than on a rolling basis. In place of minting DOIs for individual forecasts we recommend using distribution sites that allow forecasts for the same model/workflow to be grouped within a project, but to still assign a unique identifier and timestamp to each forecast (e.g., global attribute iteration_id, Table 1). This recommendation of periodic archiving is consistent with existing processes among other ecological data producers. For example, NEON data resources are continually updated with a latency ranging from \<1 day to ~1 year depending on the data product and the amount of post-processing required. Because of this, real-time NEON data are treated as provisional, with updates and corrections being introduced on-the-fly as needed. Anyone using these provisional data in publications is encouraged to archive a copy of the data they actually used. At the end of each year, NEON tags an “official” version of the data, which is assigned a persistent DOI that users can reference in lieu of creating their own archives. Analogous approaches distinguishing provisional and archival data are in common use in other disciplines as well (e.g., climate data). Our proposal for ecological forecast archives would have the same behaviors. 

## Platforms for forecast distribution and archiving

In terms of both persistent archives and real-time distribution services, we recommend that both have the following attributes:

1. **Publicly available (Open)**
EFI strongly recommends that forecasts be archived publicly under permissive, community-supported open licenses (e.g., Creative Commons, CC0; Open Data Commons Public Domain Dedication and License, PDDL) that make it clear how/if forecasts can be used, analyzed, and redistributed. First, public archiving ensures that forecasts are FAIR and usable by the largest number of end users. Second, public archiving is key to forecasts acting as out-of-sample tests that public archives provide a way of verifying that forecasts were indeed made a priori, and are not post-hoc modeling exercises. Third, public archiving of forecasts forms the basis for providing credit and transitive credit for forecasts. Fourth, public archiving is key to allowing third-party verification of forecast accuracy and precision. Although EFI recommends public archiving, we also acknowledge that, just as with archiving raw data, a range of circumstances exist where it would be unethical to publicly archive a forecast [@hobday_ethical_2019], for example if it disclosed information that could threaten a sensitive species or violated the CARE Principles for Indigenous Data Governance [@carroll_care_2020].

2. **Machine readable (Read)**
A common feature of forecasts is that any particular automated workflow tends to make a lot of them. Forecasts that are only accessible through human-readable web interfaces quickly become difficult to use when one needs to download large numbers of forecasts or when one is using forecasts as inputs into other tools and analyses. At a minimum, repositories can facilitate machine access by keeping things as simple as possible; for example, by streamlining or eliminating authentication, minimizing redirects, and ensuring URLs follow predictable patterns. These relatively simple repositories allow users to leverage network-based file access increasingly supported by many common data access libraries (e.g., most data analysis libraries can stream plain-text data directly from a URL; Python’s fsspec library; Geospatial Data Abstraction Library [GDAL] network-based file system feature). Application Programming Interfaces (APIs) are also useful for search and discovery (i.e., for generating a list of direct access URLs), and for server-side data subsetting (e.g., Data Access Protocol, DAP). Creation of such repositories is facilitated by the existence of open-source tools that can be deployed to provide many of these services to an existing data server, such as THREDDS (https://www.unidata.ucar.edu/software/tds/current/), Hyrax (https://www.opendap.org/software/hyrax-data-server), and ERDDAP (https://coastwatch.pfeg.noaa.gov/erddap/index.html) for DAP services or minIO (https://min.io/) for a more generic interface. Repositories may also benefit from leveraging managed storage and compute platforms from publicly funded (e.g., Open Storage Network) or commercial (e.g., Amazon Web Services, Google Cloud, Microsoft Azure) providers. Looking forward, extending the EFI standard to cloud-native formats (e.g., zarr, parquet, cloud-optimized GeoTIFF) would make them even easier to analyze. Finally, as noted earlier, it is also important that distribution services be machine writable, but this is less important for a persistent archive because archiving is done less frequently and files can be submitted manually rather than as part of automated workflows.

3. **Metadata is searchable (Search)**
Because many repositories are designed to be flexible and do not require specific file formats or metadata standards, they can end up with limited search capacities. Consistent with the FAIR principle that forecasts should be Findable, we recommend using repositories that take advantage of the EFI standard metadata by making that metadata searchable.

Because creating and maintaining an effective data server is a non-trivial task, forecast data providers may want to consider existing data repositories that support these attributes  (e.g., EDI, Dryad, Figshare, OSF, Zenodo).

The one notable difference between ecological forecasts and the examples at the end of the previous section (NEON, climate data, etc.) is that many (if not most) ecological forecasters end up relying on two different services for archiving versus distribution. On the archiving side, ecologists tend to rely on third-party services for the persistent archiving (e.g., Environmental Data Initiative [EDI]), similar to how ecologists rely on such archives for ecological data, rather than archiving forecasts “in house” the way that most weather forecasting centers do. This is largely a reflection of a difference in scale and resources.

On the distribution side, most iterative ecological forecasts are currently being distributed using custom problem-specific systems and portals. That said, the development of such portals often represents redundant efforts, and creates both barriers to entry and increased maintenance costs. As the ecological forecasting enterprise increases in scale and scope, there is an argument in favor of developing shared community infrastructure for forecast distribution (Fer et al. 2021). A growing number of cloud-based alternatives exist for short-term distribution that may be more accessible than a custom engineered platform. Some ecological forecasters have made use of cloud-based version control systems such as GitHub [@white_developing_2019], although it should be noted that these systems are not optimized for storing large data volumes so are best suited for smaller forecasts. A broader suite of tools is also available through the Open Science Foundation and CyVerse, which both support larger data volumes. Similarly, EFI itself has developed a cloud-based platform in support of our NEON EcologicalForecasting Challenge that leverages the EFI output and metadata standards to provide a richer suite of services including provisioning of input and target data, upload of forecasts, forecast scoring and visualization, and forecast distribution. Although the EFI platform is not currently available as a distribution service for the broader set of possible ecological forecasts, the system is available on GitHub (https://github.com/eco4cast/challenge-ci) as a container-based Docker stack that is easily redeployable. Lasty, a wide range of commercial and academic cloud-based data stores (e.g., Amazon Web Services, NSF Jetstream, Open Storage Network) are available that are capable of storing and publicly redistributing very large data volumes.

## Code and workflow archiving

Although the bulk of this paper has focused on the forecast output files and metadata, true transparency and reproducibility requires archiving the underlying models and workflows. Therefore, EFI recommends a three tiered system to forecast archiving: forecast outputs and metadata (described above); code; and operational workflows (e.g., using containers). 

### Code
Archiving code is important to provide transparency, verification, and repeatability. It also makes it much easier for others to build upon previous work. When it comes to forecasting, it is important to note that the forecast is usually generated by a whole workflow, not just by the model within that workflow. Thus, it is important to archive not just the code for the model used, but also the code for the workflow surrounding that model (e.g., data ingest, assimilation, and postprocessing). This is particularly important if any sort of iterative data assimilation algorithm is used, as the forecast can sometimes be more sensitive to the data constraints and assimilation algorithm used than to the exact structure of the model itself. EFI specifically recommends that forecasting code:
* be publicly archived,
* be well documented, both internally (e.g., ROxygen/Doxygen function documentation) and externally (READMEs and tutorials),
* be human readable (i.e., adhere to best practices and language specific conventions for formatting), and
* have a DOI issued when new versions are released.

In particular, we recommend issuing a new DOI any time the model or workflow has changed enough that two forecasts from the same system would not be considered equivalent / comparable (i.e., any time there is a new model_version). Implicitly, users need to operate under the assumption that forecasts generated under a single DOI can be analyzed together.
Releasing code under a license that would allow a reasonable degree of reuse would also provide a wide range of benefits (e.g., for reproducibility, verification, and building on previous research), however more restrictive licenses (e.g., for commercial ecological forecasting ventures) are not prohibited under the EFI convention.  Similarly, the use of open source programming languages (e.g., R, Python, C) can be beneficial for developing forecasts because these languages generally allow for independent validation and model/workflow reuse.
A common project pattern might involve developing code using a version control system (e.g., GitHub) that creates a (preferably public) record of how the model and workflow were engineered, with that development often occurring on a specific ‘devel’ branch. Periodically, this code would be pushed to the ‘main’ branch of the forecast workflow, becoming the new operational forecast. At that point, the code would be tagged with a new version number and also be pushed to a more permanent archive (e.g., Zenodo) that would mint it a new DOI. The forecast metadata \<model_name\> would then be updated with this new DOI.

### Operational Workflows

The final tier of the EFI forecast archiving standard is to archive the operational workflow itself. Doing so is important because experience shows that it can be difficult (and sometimes impossible) for others to successfully build and run other peoples’ models and workflows. This difficulty can occur because of steep learning curves, differences in operating system, and (often undocumented) requirements for specific versions of libraries. A range of options have emerged to deal with these problems (see, for example, the EFI Task View on Reproducible Workflows, https://projects.ecoforecast.org/taskviews/reproducible-forecasting-workflows.html). One approach is to use dependency management tools (e.g., renv or packrat in R; pip or poetry libraries in Python; or language-agnostic tools like conda), which aim to track the specific versions of all dependencies in a workflow. Another approach is virtualization – to encapsulate the entire system, from operating system on up, inside a ‘virtual machine’ that completely isolates the virtual system from the host computer it is running on. Virtual machines (VMs) are highly portable because the same VM can run on any computer regardless of the operating system of the host itself. However, VMs have the disadvantage of being fairly large and slow to launch. A more recent variant on the virtualization idea is ‘containerization,’ which continues this idea of isolating software and its dependencies in a portable, platform-independent way, but tends to be more lightweight than a full VM (e.g., Docker, Singularity). To increase interoperability, EFI standard currently recommends using containers for workflow reproducibility. The most straightforward way to do this is to put both the workflow and model inside the container, but it is also acceptable to have the model code in a separate repository that needs to be pulled into the container, so long as the specific version of container and code are clearly documented.

Beyond just putting a workflow into a container (or stack of containers), it is important to consider the inputs and outputs of that container. Standardizing these reduces the barriers to re-use and makes it easier to perform larger, synthetic analyses (e.g., uncertainty partitioning). The EFI Theory Working Group specifically chose to recommend containerization, over providing detailed protocols, as a way of facilitating cross-cutting uncertainty and transferability analyses [@lewis_power_2023]. Specifically, we recommend that forecast containers return EFI standard output files and metadata.

Currently, the EFI standard does not yet provide a general specification for how driver, initial condition, parameter, random effect, and process error files should be passed into containers. Although not formally part of the EFI standard, the NEON Ecological Forecasting Challenge has adopted an internal standard for “target” files, which contain the observational data used for scoring and which could also be used for model calibration or iterative data assimilation [@thomas_ecological_2021]. Overall, the standards required to support a front-to-back ecological forecasting workflow are still a work in progress and we plan to provide greater detail in future versions of this standard. In the meantime users can create model containers with this set of inputs in mind. Likewise we encourage the development of a larger set of workflow containers with the provisioning of these files in mind. The PEcAn Project (pecanproject.org) represents a current example of such an integrated system with standards for meteorological drivers (netCDF-CF), soils (netCDF CF-compliant), parameters (BETY database), initial conditions, and data constraints, as well as standard workflows for generating these files [@fer_beyond_2021].